{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_encoded is [3 3 3 ... 0 0 0]\n",
      "Training set distribution: Counter({0: 324, 1: 324, 2: 324, 3: 324, 4: 324})\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "min() received an invalid combination of arguments - got (Tensor, Tensor, Tensor), but expected one of:\n * (Tensor input)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(y_pred)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mknn_classify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Evaluate accuracy\u001b[39;00m\n\u001b[1;32m    127\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "Cell \u001b[0;32mIn[1], line 112\u001b[0m, in \u001b[0;36mknn_classify\u001b[0;34m(X_train, y_train, X_test, k)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_sample \u001b[38;5;129;01min\u001b[39;00m X_train:\n\u001b[1;32m    111\u001b[0m     train_sample_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_sample, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 112\u001b[0m     distance \u001b[38;5;241m=\u001b[39m \u001b[43mdtw_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sample_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_sample_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     distances\u001b[38;5;241m.\u001b[39mappend(distance\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    114\u001b[0m distances \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(distances, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 97\u001b[0m, in \u001b[0;36mdtw_distance\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, M\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     96\u001b[0m         cost \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(x[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m y[j\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 97\u001b[0m         dtw_matrix[i, j] \u001b[38;5;241m=\u001b[39m cost \u001b[38;5;241m+\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtw_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtw_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtw_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m     \u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtw_matrix[N, M]\n",
      "\u001b[0;31mTypeError\u001b[0m: min() received an invalid combination of arguments - got (Tensor, Tensor, Tensor), but expected one of:\n * (Tensor input)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "#KNN + DWT + GPU\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "\n",
    "# Load data\n",
    "data_path = '../DATA/labeled_window_dataset.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    " # Define columns corresponding to each joint\n",
    "joint_columns = {\n",
    "    0: ['e0', 'de0', 'tau_J0', 'tau_ext0'],\n",
    "    1: ['e1', 'de1', 'tau_J1', 'tau_ext1'],\n",
    "    2: ['e2', 'de2', 'tau_J2', 'tau_ext2'],\n",
    "    3: ['e3', 'de3', 'tau_J3', 'tau_ext3'],\n",
    "    4: ['e4', 'de4', 'tau_J4', 'tau_ext4'],\n",
    "    5: ['e5', 'de5', 'tau_J5', 'tau_ext5'],\n",
    "    6: ['e6', 'de6', 'tau_J6', 'tau_ext6'],\n",
    "}\n",
    "\n",
    "# Initialize feature and label lists\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Group data by 'block_id'\n",
    "grouped = df.groupby('window_id')\n",
    "\n",
    "\n",
    "# Process each group\n",
    "for window_id, group in grouped:\n",
    "   \n",
    "    # print(f\"group is {group}\")\n",
    "    # Initialize an empty list to hold the features for this block\n",
    "    window_features = []\n",
    "    \n",
    "    # Concatenate data for each joint\n",
    "    for joint, cols in joint_columns.items():\n",
    "        # print(f\"joint is {joint}\")\n",
    "        # print(f\"cols is {cols}\")\n",
    "        joint_data = group.loc[:, cols].values.flatten()  \n",
    "        window_features.extend(joint_data)  \n",
    "        \n",
    "    X_list.append(window_features)\n",
    "    # print(f\"X_list is {X_list}\")\n",
    "    y_list.append(group['window_touch_type'].iloc[0])  \n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X_list)\n",
    "# print(f\"X is {X} and length is {len(X)}\")\n",
    "y = np.array(y_list)\n",
    "# print(f\"y is {y} and length is {len(y)}\") \n",
    " \n",
    "# Encode labels\n",
    "label_classes = { \"NC\":0,\"ST\":1, \"DT\":2, \"P\":3,\"G\":4}\n",
    "# print(f\"label_classes is {label_classes}\")\n",
    "label_map = {key:value for key, value in label_classes.items()}\n",
    "y_encoded = np.array([label_map[key] for key in y])\n",
    "print(f\"y_encoded is {y_encoded}\")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled,y_resampled = undersampler.fit_resample(X_train,y_train)\n",
    "print(\"Training set distribution:\", Counter(y_resampled))\n",
    "\n",
    "# # Define hyperparameters grid\n",
    "# param_grid = {\n",
    "#     'n_neighbors': list(range(1, 21)),\n",
    "#     'weights': ['uniform', 'distance']\n",
    "# }\n",
    "\n",
    "def dtw_distance(x, y):\n",
    "    # 假设 x 和 y 是在 GPU 上的 Tensor，形状为 (seq_len,)\n",
    "    N, M = len(x), len(y)\n",
    "    dtw_matrix = torch.full((N+1, M+1), float('inf'), device='cuda')\n",
    "    dtw_matrix[0, 0] = 0\n",
    "\n",
    "    for i in range(1, N+1):\n",
    "        for j in range(1, M+1):\n",
    "            cost = torch.abs(x[i-1] - y[j-1])\n",
    "            dtw_matrix[i, j] = cost + torch.min(\n",
    "                dtw_matrix[i-1, j],      \n",
    "                dtw_matrix[i, j-1],      \n",
    "                dtw_matrix[i-1, j-1]     \n",
    "            )\n",
    "    return dtw_matrix[N, M]\n",
    "\n",
    "# K-NN classifier using DTW\n",
    "def knn_classify(X_train, y_train, X_test, k):\n",
    "    y_pred = []\n",
    "    for test_sample in X_test:\n",
    "        distances = []\n",
    "        test_sample_tensor = torch.tensor(test_sample, device='cuda', dtype=torch.float32)\n",
    "        for train_sample in X_train:\n",
    "            train_sample_tensor = torch.tensor(train_sample, device='cuda', dtype=torch.float32)\n",
    "            distance = dtw_distance(test_sample_tensor, train_sample_tensor)\n",
    "            distances.append(distance.item())\n",
    "        distances = torch.tensor(distances, device='cuda')\n",
    "        # Get the k-nearest neighbors\n",
    "        _, indices = torch.topk(distances, k, largest=False)\n",
    "        nearest_labels = y_train[indices.cpu()]\n",
    "        # Majority vote\n",
    "        prediction = Counter(nearest_labels).most_common(1)[0][0]\n",
    "        y_pred.append(prediction)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Predict\n",
    "y_pred = knn_classify(X_resampled,y_resampled,X_test,5)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Print predicted and true labels\n",
    "print(f'Predicted labels: {y_pred}')\n",
    "print(f'True labels: {y_test}')\n",
    "\n",
    "# Display classification report\n",
    "print(classification_report(y_test, y_pred, target_names=label_classes.keys()))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure()\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_classes, yticklabels=label_classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
